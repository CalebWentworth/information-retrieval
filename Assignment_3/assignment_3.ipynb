{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbgPtoQ3ASV6"
      },
      "outputs": [],
      "source": [
        "%pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23H3MwoeGaN3"
      },
      "outputs": [],
      "source": [
        "%pip install -U datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yZlGL_S6AQMU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/caleb/school/information-retrieval/Assignment_3/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine-Similarity: tensor([[0.6366]])\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "#Sentences are encoded by calling model.encode()\n",
        "emb1 = model.encode(\"Information Retrieval course at the University of Southern Maine for computer scientist.\")\n",
        "emb2 = model.encode(\"Best computer science course.\")\n",
        "\n",
        "cos_sim = util.cos_sim(emb1, emb2)\n",
        "print(\"Cosine-Similarity:\", cos_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import datetime\n",
        "import json\n",
        "import string\n",
        "from bs4 import BeautifulSoup\n",
        "from argparse import ArgumentParser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def remove_html(string):\n",
        "    cleantext = BeautifulSoup(string, \"lxml\").text\n",
        "    return cleantext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_topic_file(topic_filepath):\n",
        "    # a method used to read the topic file for this year of the lab; to be passed to BERT/PyTerrier methods\n",
        "    queries = json.load(open(topic_filepath))\n",
        "    result = {}\n",
        "    for item in queries:\n",
        "      # returing results as dictionary of topic id: [title, body, tag]\n",
        "      title =  item['Title'].translate(str.maketrans('', '', string.punctuation))\n",
        "      #removing html from body\n",
        "      body = remove_html(item['Body']).translate(str.maketrans('', '', string.punctuation))\n",
        "      tags = item['Tags']\n",
        "      result[item['Id']] = [title, body, tags]\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_qrel_file(qrel_filepath):\n",
        "    # a method used to read the topic file\n",
        "    result = {}\n",
        "    with open(qrel_filepath, \"r\") as f:\n",
        "        reader = csv.reader(f, delimiter='\\t', lineterminator='\\n')\n",
        "        for line in reader:\n",
        "            query_id = line[0]\n",
        "            doc_id = line[2]\n",
        "            score = int(line[3])\n",
        "            if query_id in result:\n",
        "                result[query_id][doc_id] = score\n",
        "            else:\n",
        "                result[query_id] = {doc_id: score}\n",
        "    # dictionary of key:query_id value: dictionary of key:doc id value: score\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_collection(answer_filepath):\n",
        "  # Reading collection to a dictionary\n",
        "  lst = json.load(open(answer_filepath))\n",
        "  result = {}\n",
        "  for doc in lst:\n",
        "    #processes the answers to remove html and punctuation.\n",
        "    result[doc['Id']] = remove_html(doc['Text']).translate(str.maketrans('', '', string.punctuation))\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#modifies each query to contain the title and body\n",
        "def prep_queries(topics):\n",
        "    queries = {}\n",
        "    for query_id in topics:\n",
        "        queries[query_id] = \"[TITLE]\" + topics[query_id][0] + \"[BODY]\" + topics[query_id][1]\n",
        "    return queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import InputExample\n",
        "\n",
        "def dataset_gen(queries,qrel,answers):\n",
        "    result_list = []\n",
        "    sample_list =[]\n",
        "    for topic in qrel:\n",
        "        print(f\"Key: {topic}, Value: {qrel[topic]}\")\n",
        "        for doc, score in qrel[topic].items():\n",
        "            pair = (queries[topic],answers[doc],score)\n",
        "            result_list.append(pair)\n",
        "\n",
        "    for pair in result_list:\n",
        "        ex_1 = pair[0]\n",
        "        ex_2 = pair[1]\n",
        "        label = pair[2]\n",
        "        if label >=1:\n",
        "            label = 1\n",
        "        sample_list.append(InputExample(texts=[pair[0],pair[1]],label=label))\n",
        "\n",
        "    return sample_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument('-i', '--input', required=True, help='search domain file e.g. Answers.json', default=\"Answers.json\")\n",
        "    parser.add_argument('-t', '--topic', required=True, help='topic source files e.g. topics_1.json', default=\"topics_1.json\")\n",
        "    parser.add_argument('-q', '--qrel', required=True, help='qrel source files e.g. qrel_1.tsv', default=\"qrel_1.tsv\")\n",
        "    args = parser.parse_args()\n",
        "    answer_filepath = args.input\n",
        "    topic_filepath = args.topic\n",
        "    qrel_filepath = args.qrel\n",
        "\n",
        "    topics = load_topic_file(topic_filepath)\n",
        "    qrel = read_qrel_file(qrel_filepath)\n",
        "    answers = read_collection(answer_filepath)\n",
        "\n",
        "    queries = prep_queries(topics)\n",
        "    \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "topics = load_topic_file(\"topics_1.json\")\n",
        "qrel = read_qrel_file(\"qrel_1.tsv\")\n",
        "answers = read_collection(\"Answers.json\")\n",
        "queries = prep_queries(topics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = dataset_gen(queries,qrel,answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#what models am i going to use:\n",
        "# multi-qa-mpnet-base-dot-v1 : apparently it preforms better on semantic search tasks.\n",
        "import random\n",
        "\n",
        "def partition(data):\n",
        "    random.shuffle(data)\n",
        "    n = len(data)\n",
        "    split1 = int(n * 0.8)\n",
        "    split2 = int(n * 0.9)\n",
        "\n",
        "    train = data[:split1]\n",
        "    validation = data[split1:split2]\n",
        "    test = data[split2:]\n",
        "\n",
        "    return train, validation, test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#partition dataset into 80:10:10 sets\n",
        "\n",
        "train_set, validation_set, test_set = partition(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers import CrossEncoder\n",
        "from sentence_transformers.losses import CoSENTLoss\n",
        "from sentence_transformers import datasets\n",
        "\n",
        "bi_model = SentenceTransformer(\"multi-qa-mpnet-base-cos-v1\")\n",
        "cross_model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "\n",
        "bi_finetune = SentenceTransformer(\"multi-qa-mpnet-base-cos-v1\")\n",
        "bi_loss = CoSENTLoss(bi_finetune)\n",
        "cross_finetune = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "cross_loss = CoSENTLoss(cross_finetune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import (\n",
        "    SentenceTransformer,\n",
        "    SentenceTransformerTrainer,\n",
        "    SentenceTransformerTrainingArguments,\n",
        "    SentenceTransformerModelCardData\n",
        ")\n",
        "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
        "from sentence_transformers import losses\n",
        "from sentence_transformers.training_args import BatchSamplers\n",
        "from sentence_transformers.cross_encoder.evaluation import (\n",
        "    CESoftmaxAccuracyEvaluator,\n",
        "    CEBinaryClassificationEvaluator,\n",
        "    CERerankingEvaluator,\n",
        "    )\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "def fine_tune_bi(model,loss,train,valid,model_name,epochs=10):\n",
        "     \n",
        "    tokens = [\"[TITLE]\", \"[BODY]\"]\n",
        "    model.tokenizer.add_tokens(tokens, special_tokens=True)\n",
        "    model.resize_token_embeddings(len(model.tokenizer))\n",
        "    args = SentenceTransformerTrainingArguments(\n",
        "        # Required parameter:\n",
        "        output_dir=\"models/\"+model_name,\n",
        "        # Optional training parameters:\n",
        "        num_train_epochs=epochs,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        learning_rate=2e-5,\n",
        "        warmup_ratio=0.1,\n",
        "        fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
        "        bf16=False,  # Set to True if you have a GPU that supports BF16\n",
        "        batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
        "    )\n",
        "    #fails with error list has no atribute info for some reason?\n",
        "    \"\"\"evaluator = CERerankingEvaluator(valid, name='train-eval')\n",
        "    trainer = SentenceTransformerTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train,\n",
        "        eval_dataset=valid,\n",
        "        loss=loss,\n",
        "        evaluator=evaluator\n",
        "    )\n",
        "    trainer.train()\n",
        "    model.save_pretrained(\"models/bi_finetuned\")\n",
        "    \"\"\"\n",
        "    num_epochs = epochs\n",
        "    model_save_path = \"models/\"+model_name\n",
        "    train_dataloader = DataLoader(train, shuffle=True, batch_size=4)\n",
        "    # During training, we use CESoftmaxAccuracyEvaluator to measure the accuracy on the dev set.\n",
        "    evaluator = CERerankingEvaluator(valid, name='train-eval')\n",
        "    warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
        "    train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
        "    train_objectives = [(train_dataloader, loss)]\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        train_objectives=train_objectives,\n",
        "        evaluator=evaluator,\n",
        "        epochs=epochs,\n",
        "        warmup_steps=warmup_steps,\n",
        "        output_path=model_save_path,\n",
        "        save_best_model=True\n",
        "    )\n",
        "    model.save(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%pip install transformers[torch]\n",
        "%pip show torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'CrossEncoder' object has no attribute 'resize_token_embeddings'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfine_tune_bi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_finetune\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcross_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_set\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfine_tuned_cross\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[18], line 23\u001b[0m, in \u001b[0;36mfine_tune_bi\u001b[0;34m(model, loss, train, valid, model_name, epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[TITLE]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[BODY]\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39madd_tokens(tokens, special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_token_embeddings\u001b[49m(\u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mtokenizer))\n\u001b[1;32m     24\u001b[0m args \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainingArguments(\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Required parameter:\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mmodel_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     batch_sampler\u001b[38;5;241m=\u001b[39mBatchSamplers\u001b[38;5;241m.\u001b[39mNO_DUPLICATES,  \u001b[38;5;66;03m# MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\u001b[39;00m\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#fails with error list has no atribute info for some reason?\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CrossEncoder' object has no attribute 'resize_token_embeddings'"
          ]
        }
      ],
      "source": [
        "fine_tune_bi(cross_finetune,cross_loss,train_set,validation_set,\"fine_tuned_cross\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5cXDMNgEEcQ"
      },
      "outputs": [],
      "source": [
        "# Fine-tuning Cross-encoder\n",
        "import csv\n",
        "import datetime\n",
        "import json\n",
        "import string\n",
        "from sentence_transformers import InputExample\n",
        "from sentence_transformers import SentenceTransformer, util, CrossEncoder, losses\n",
        "import torch\n",
        "from sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator, CEBinaryClassificationEvaluator, \\\n",
        "    CERerankingEvaluator\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "\n",
        "## reading queries and collection\n",
        "#dic_topics is just the query file\n",
        "dic_topics = load_topic_file(\"topics_1.json\")\n",
        "queries = {}\n",
        "#modifies each query to contain the tags title and body\n",
        "for query_id in dic_topics:\n",
        "    queries[query_id] = \"[TITLE]\" + dic_topics[query_id][0] + \"[BODY]\" + dic_topics[query_id][1]\n",
        "qrel = read_qrel_file(\"qrel_1.tsv\")\n",
        "collection_dic = read_collection('Answers.json')\n",
        "\n",
        "## Preparing pairs of training instances\n",
        "num_topics = len(queries.keys())\n",
        "number_training_samples = int(num_topics*0.9)\n",
        "\n",
        "\n",
        "## Preparing the content\n",
        "counter = 1\n",
        "train_samples = []\n",
        "valid_samples = {}\n",
        "for qid in qrel:\n",
        "    # key: doc id, value: relevance score\n",
        "    dic_doc_id_relevance = qrel[qid]\n",
        "    # query text\n",
        "    topic_text = queries[qid]\n",
        "\n",
        "    if counter < number_training_samples:\n",
        "        for doc_id in dic_doc_id_relevance:\n",
        "            label = dic_doc_id_relevance[doc_id]\n",
        "            content = collection_dic[doc_id]\n",
        "            if label >= 1:\n",
        "                label = 1\n",
        "            train_samples.append(InputExample(texts=[topic_text, content], label=label))\n",
        "    else:\n",
        "        for doc_id in dic_doc_id_relevance:\n",
        "            label = dic_doc_id_relevance[doc_id]\n",
        "            if qid not in valid_samples:\n",
        "                valid_samples[qid] = {'query': topic_text, 'positive': set(), 'negative': set()}\n",
        "            if label == 0:\n",
        "                label = 'negative'\n",
        "            else:\n",
        "                label = 'positive'\n",
        "            content = collection_dic[doc_id]\n",
        "            valid_samples[qid][label].add(content)\n",
        "    counter += 1\n",
        "\n",
        "print(\"Training and validation set prepared\")\n",
        "\n",
        "# selecting cross-encoder\n",
        "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "# Learn how to use GPU with this!\n",
        "model = CrossEncoder(model_name)\n",
        "\n",
        "# Adding special tokens\n",
        "tokens = [\"[TITLE]\", \"[BODY]\"]\n",
        "model.tokenizer.add_tokens(tokens, special_tokens=True)\n",
        "model.model.resize_token_embeddings(len(model.tokenizer))\n",
        "\n",
        "num_epochs = 2\n",
        "model_save_path = \"./ft_cr_2024\"\n",
        "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=4)\n",
        "# During training, we use CESoftmaxAccuracyEvaluator to measure the accuracy on the dev set.\n",
        "evaluator = CERerankingEvaluator(valid_samples, name='train-eval')\n",
        "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
        "model.fit(train_dataloader=train_dataloader,\n",
        "          evaluator=evaluator,\n",
        "          epochs=num_epochs,\n",
        "          warmup_steps=warmup_steps,\n",
        "          output_path=model_save_path,\n",
        "          save_best_model=True)\n",
        "\n",
        "model.save(model_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "052gC8QAruIi"
      },
      "outputs": [],
      "source": [
        "# Fine-tuning Bi-encoder\n",
        "# Models: https://sbert.net/docs/sentence_transformer/pretrained_models.html\n",
        "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, losses, evaluation\n",
        "from torch.utils.data import DataLoader\n",
        "from itertools import islice\n",
        "import json\n",
        "import torch\n",
        "import math\n",
        "import string\n",
        "import csv\n",
        "import random\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "def read_qrel_file(file_path):\n",
        "    # Reading the qrel file\n",
        "    dic_topic_id_answer_id_relevance = {}\n",
        "    with open(file_path) as fd:\n",
        "        rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
        "        for row in rd:\n",
        "            topic_id = row[0]\n",
        "            answer_id = int(row[2])\n",
        "            relevance_score = int(row[3])\n",
        "            if topic_id in dic_topic_id_answer_id_relevance:\n",
        "                dic_topic_id_answer_id_relevance[topic_id][answer_id] = relevance_score\n",
        "            else:\n",
        "                dic_topic_id_answer_id_relevance[topic_id] = {answer_id: relevance_score}\n",
        "    return dic_topic_id_answer_id_relevance\n",
        "\n",
        "\n",
        "def load_topic_file(topic_filepath):\n",
        "    # a method used to read the topic file for this year of the lab; to be passed to BERT/PyTerrier methods\n",
        "    queries = json.load(open(topic_filepath))\n",
        "    result = {}\n",
        "    for item in queries:\n",
        "      # You may do additional preprocessing here\n",
        "\n",
        "      # returing results as dictionary of topic id: [title, body, tag]\n",
        "      title = item['Title'].translate(str.maketrans('', '', string.punctuation))\n",
        "      body = item['Body'].translate(str.maketrans('', '', string.punctuation))\n",
        "      tags = item['Tags']\n",
        "      result[item['Id']] = [title, body, tags]\n",
        "    return result\n",
        "\n",
        "\n",
        "def read_collection(answer_filepath):\n",
        "  # Reading collection to a dictionary\n",
        "  lst = json.load(open(answer_filepath))\n",
        "  result = {}\n",
        "  for doc in lst:\n",
        "    result[int(doc['Id'])] = doc['Text']\n",
        "  return result\n",
        "\n",
        "\n",
        "# Uses the posts file, topic file(s) and qrel file(s) to build our training and evaluation sets.\n",
        "def process_data(queries, train_dic_qrel, val_dic_qrel, collection_dic):\n",
        "    train_samples = []\n",
        "    evaluator_samples_1 = []\n",
        "    evaluator_samples_2 = []\n",
        "    evaluator_samples_score = []\n",
        "\n",
        "    # Build Training set\n",
        "    for topic_id in train_dic_qrel:\n",
        "        question = queries[topic_id]\n",
        "        dic_answer_id = train_dic_qrel.get(topic_id, {})\n",
        "\n",
        "        for answer_id in dic_answer_id:\n",
        "            score = dic_answer_id[answer_id]\n",
        "            answer = collection_dic[answer_id]\n",
        "            if score > 1:\n",
        "                train_samples.append(InputExample(texts=[question, answer], label=1.0))\n",
        "            else:\n",
        "                train_samples.append(InputExample(texts=[question, answer], label=0.0))\n",
        "    for topic_id in val_dic_qrel:\n",
        "        question = queries[topic_id]\n",
        "        dic_answer_id = val_dic_qrel.get(topic_id, {})\n",
        "\n",
        "        for answer_id in dic_answer_id:\n",
        "            score = dic_answer_id[answer_id]\n",
        "            answer = collection_dic[answer_id]\n",
        "            if score > 1:\n",
        "                label = 1.0\n",
        "            elif score == 1:\n",
        "                label = 0.5\n",
        "            else:\n",
        "                label = 0.0\n",
        "            evaluator_samples_1.append(question)\n",
        "            evaluator_samples_2.append(answer)\n",
        "            evaluator_samples_score.append(label)\n",
        "\n",
        "    return train_samples, evaluator_samples_1, evaluator_samples_2, evaluator_samples_score\n",
        "\n",
        "\n",
        "\n",
        "def shuffle_dict(d):\n",
        "    keys = list(d.keys())\n",
        "    random.shuffle(keys)\n",
        "    return {key: d[key] for key in keys}\n",
        "\n",
        "\n",
        "def split_train_validation(qrels, ratio=0.9):\n",
        "    # Using items() + len() + list slicing\n",
        "    # Split dictionary by half\n",
        "    n = len(qrels)\n",
        "    n_split = int(n * ratio)\n",
        "    qrels = shuffle_dict(qrels)\n",
        "    train = dict(islice(qrels.items(), n_split))\n",
        "    validation = dict(islice(qrels.items(), n_split, None))\n",
        "\n",
        "    return train, validation\n",
        "\n",
        "\n",
        "def train(model):\n",
        "\n",
        "    ## reading queries and collection\n",
        "    dic_topics = load_topic_file(\"topics_1.json\")\n",
        "    queries = {}\n",
        "    for query_id in dic_topics:\n",
        "        queries[query_id] = \"[TITLE]\" + dic_topics[query_id][0] + \"[BODY]\" + dic_topics[query_id][1]\n",
        "    qrel = read_qrel_file(\"qrel_1.tsv\")\n",
        "    collection_dic = read_collection('Answers.json')\n",
        "    train_dic_qrel, val_dic_qrel = split_train_validation(qrel)\n",
        "\n",
        "    # print(train_dic_qrel)\n",
        "    # print(val_dic_qrel)\n",
        "\n",
        "    num_epochs = 100\n",
        "    batch_size = 16\n",
        "\n",
        "    # Rename this when training the model and keep track of results\n",
        "    MODEL = \"SAVED_MODEL_NAME\"\n",
        "\n",
        "    # Creating train and val dataset\n",
        "    train_samples, evaluator_samples_1, evaluator_samples_2, evaluator_samples_score = process_data(queries, train_dic_qrel, val_dic_qrel, collection_dic)\n",
        "\n",
        "    train_dataset = SentencesDataset(train_samples, model=model)\n",
        "    train_dataloader = DataLoader(train_dataset, shuffle = True, batch_size=batch_size)\n",
        "    train_loss = losses.CosineSimilarityLoss(model=model)\n",
        "\n",
        "    evaluator = evaluation.EmbeddingSimilarityEvaluator(evaluator_samples_1, evaluator_samples_2, evaluator_samples_score, write_csv=\"evaluation-epoch.csv\")\n",
        "    warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
        "\n",
        "    # add evaluator to the model fit function\n",
        "    model.fit(\n",
        "        train_objectives =[(train_dataloader, train_loss)],\n",
        "        evaluator=evaluator,\n",
        "        epochs=num_epochs,\n",
        "        warmup_steps=warmup_steps,\n",
        "        use_amp=True,\n",
        "        save_best_model=True,\n",
        "        show_progress_bar=True,\n",
        "        output_path=MODEL\n",
        "    )\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "train(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import trectools\n",
        "import pyterrier as pt\n",
        "\n",
        "#Goal Produce 4 models: \n",
        "#Bi-encoder with fine tuing\n",
        "#Bi-Encoder with no finetuning\n",
        "#Cross-Encoder with finetuing\n",
        "#cross-Encoder with non finetuing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': '[TITLE]Are there any issues with using credit cards in Germany[BODY]pOn my last trip to Germany my credit cards chipbased Visa and MasterCard were declined more than usual Ive been there like 10 times and havent noticed this before but on this trip train ticket machines refused to service them small shops didnt accept them and even a huge consumer electronics network store Mediamarkt said EC cards only Whatever EC card isppHas anything changed in regard to credit cards in Germany in recent years or was I just unlucky this time And whats the root of this problem As far as I understand these chipbased credit cards technically are not that different if at all from debitatm cardsp', 'positive': {'<p>This question is from 2011 and things have improved, even in Germany. As of 2016 you can survive using credit card payments only, but there are still plenty of places that do not accept them. </p><p>As a rule of thumb a credit card is more likely to be accepted if</p><ul><li>you are in a metropolitan/touristy area</li><li>with hotel/supermarket/... chains</li><li>for larger sums of money (e.g. at least 20€)</li><li>Mastercard and Visa are commonly accepted, less so American Express and even less Diners Club</li></ul><p>This means if you are going to stay with a family-run no-frills hotel in a small town or get a snack from a bakery you should better have an alternative way of payment. </p><p>Paying cash still is the norm in Germany for everyday use and people carry more cash compared to e.g. the US - carrying 50-100€ in cash on a regular day (depending on your daily spend) is normal and even more if travelling. If paying by card the standard is the EC-card which would likely be issued by a German bank and works in Europe only. Especially older people use their cards to withdraw money once a month and use cash only. </p><p>Likelihood of acceptance of credit cards by spending categories: [keep in mind the general comments above as well]</p><ul><li>ATMs: should accept your card for withdrawals</li><li>Supermarkets: <a href=\"https://gedankenausbruch.com/tipps-tricks/allgemeine-kreditkartenakzeptanz-bei-supermaerkten-offline/\" rel=\"noreferrer\">here you can find an overview</a>, in a nutshell as of the end of 2015 all major supermarkets, including discounters, accept Mastercard and Visa</li><li>Train tickets: you should be able to buy train tickets online, at the counter and at most ticket machines with a Visa or Mastercard</li><li>local public transport: depends on the city. Better in major cities, where you could also buy tickets for local transport at the train ticket machines of DB</li><li>taxi: depends on the city, don\\'t rely on it. At least in Berlin drivers have to accept it, otherwise they are not allowed to carry passengers (but they do charge a small fee for paying by credit card)</li><li>hotels: even in larger cities some small hotels on the lower end of the price spectrum do not accept cards at all. They are usually quite forward about it but read the conditions/fine print when booking. </li><li>restaurants: I would not bet on a regular place where Germans go to eat in the 10-20€ range to accept credit cards. Changes a lot if you go upscale of course or McDonalds and the likes. </li></ul><p>N.b. the recent improvement in credit card acceptance is due to <a href=\"http://www.consilium.europa.eu/en/press/press-releases/2015/04/20-capping-fees-card-based-payments/\" rel=\"noreferrer\">new EU regulation</a> capping card fees for merchants since 2015. This triggered the increased acceptance at supermarkets and expect further improvements in the future. </p>', '<p>Credit Cards in Germany are as useful as stones when it comes to paying for goods. Either get cash from you credit card in a real bank during business hours <strike>(Most ATMs only handle EC cards)</strike>, or get your own EC card if you plan to stay longer. </p><p>I was working for a shop in Germany a few years ago and they wanted to accept credit cards for internet payments; however the payment provider charged way too much for this service (5% transaction fee or so?) so that\\'s probably one of the reasons why credit cards are not popular in most stores.</p><p>The other difference for the customer is that most banks only let you spend the money you have in your account when using EC cards, so you don\\'t get credit but a \"not enough funds\" message when you run out of money. However you can apply for an overdraft limit (called \"dispolimit\" in German) on EC cards, or your account for that matter.</p>', '<p>On a recent trip to Germany (Berlin) (December 2015), my Mastercard Debit card (Chip + Pin) was accepted in all large stores (Karstadt, Ullrich, Kaufland), as well as the BVG Mobile App, but notably not in the U-Bahn ticket machines (per <a href=\"https://www.bvg.de/en/Tickets/Other-ways-to-buy/At-ticket-machines\">https://www.bvg.de/en/Tickets/Other-ways-to-buy/At-ticket-machines</a>, payment is accepted only in cash or with EC card).</p><p>ATMs allowed me to withdraw cash, I didn\\'t have any problems with them not accepting the Mastercard.</p>', '<p>In short: yes (there will be issues).</p><p>Mostly, credit card acceptance in Germany is still the exception rather than the norm. There are a couple of places, however, where you can expect at least Visa and MC to be accepted, most notably ATMs and gas stations.</p><p>Be prepared to pay in cash everywhere else.</p>', '<p>I am in a small village in Germany right now and my Spanish Debit card (MC)  only works to get money from the bank and in some major restaurants. No supermarkets or small bars accept it.</p>', \"<p>In Germany, and many other European countries except for the UK, Maestro is the de facto card-payment method. Many shops do not accept credit cards and if they do, Visa and MasterCard are more widely accepted than AmEx. Now, that does not mean you'll have to pay cash everywhere. Recently (somewhere in 2015) more shops started accepting credit cards. This includes most bigger shops and warehouses and restaurants. Smaller shops are hit and miss, since the shops often have to account for increased transaction costs. </p><p>While a credit card should work nearly everywhere where moderate to big payments are done, you should probably also bring a Maestro card or some cash. Every ATM should accept the 3 biggest cards and there are many possibilities to get a Maestro card. </p><p>Note: some small shops will accept NFC payments by phone but no credit cards, although these are somewhat uncommon. </p>\", \"<p>I am from the US and currently traveling through Germany. I've found that hotels and rental car agencies have no problems with my chip+signature Visa (I have 3 cards, all from Chase).</p><p>What has been frustrating for me is that I cannot use my credit card to purchase DB tickets, either from the website or in person. The website only tells me that the CVV is wrong. I called up both Chase and Visa and they tell me that they didn't even receive a query and that I should go in person and have the agent manually key in my credit card info.  (The agent's English was really good, but not that good, so I ended up paying in cash.)</p>\", \"<p>A good solution for me (located in Germany) was to create an account at an online bank like DKB or ING-Diba which is for free. You then get a credit card which you can use at every ATM in Europe or in case of ING-Diba worldwide to get cash without paying fees. The cards are chip based and can be used - if credit card payment is accepted - everywhere for payment. If not you can get cash at the ATM. </p><p>If payment is accepted, you can also get cash when paying for goods. Just say to the clerk that you also need a certain amount of money in cash. You'll get it and your card will be charged with this amount. You can avoid using ATMs/paying fees or save time this way.</p><p>If you use these smaller ATMs placed at street corners in Germany be aware of skimming! My account got blocked because of this and I know several people who had the same issue with these kind of ATMs. </p>\", \"<p>A core reason is that shops don't like to accept them, so much that they sometimes even 'fake' that they fail (even disconnect the machine and claim it won't work); or give a discount for higher priced articles when asked. The fees to them are high (as in other countries), but in Germany specially, the EC card (just like a <em>debit card</em>) has taken over the market completely. Most Germans have <em>no</em> credit cards, or only use them while vacationing; many dislike the concept; and some don't even know what it is. Also, until about last year (~2014), German credit cards didn't work like US credit cards; rather you were <em>required</em> to have an automatic full payment by deduction every month from your checking account (which makes them even more unattractive).</p><p>Hotels, car rental, mid- to high-level restaurant, and chains do generally accept credit cards (foreign as well as German cards). recently, several supermarket chains have also started to accept them, so it is moving to a much broader acceptance.</p><p>[I am German, btw., but live in the US, so I know both sides well.]</p>\", '<blockquote><p><strong>Edit:</strong> There is an interesting question over at <a href=\"https://money.stackexchange.com/questions/3203/how-can-americans-get-a-chip-and-pin-credit-card-for-use-while-abroad\">money.stackexchange.com</a> explaining that US-issued magnetic stripe credit cards do not work in many european machines that require the card to have a chip:</p><blockquote><p>Sometimes it works, more often it doesn\\'t. I challenge you to buy a train ticket from a machine anywhere in Europe. It was particularly unnerving on a highway in France trying to pay the toll from a machine which didn\\'t take cash at an unattended toll booth... none of my credit cards worked except, oddly, American Express.</p></blockquote></blockquote><p>Germany is indeed a developing country as far as Credit Cards are concerned. Things are changing, at least for Amex, Visa, and Mastercard - but slowly.</p><p>Some exceptions:</p><ul><li><p>Supermarket chain <a href=\"http://rewe.de\" rel=\"noreferrer\">REWE</a> accepts credit cards in most, if not all, stores. There may be a minimum purchase imposed by the local franchisee, I have seen €5 and €10 amounts.</p></li><li><p>I have never had any problems buying Deutsche Bahn train tickets with various credit cards (Visa, Mastercard). I cannot testify to how cards issued in other countries are accepted, but  there <em>shouldn\\'t</em> be any problems. (Turns out there may be - see edit above.)</p></li><li><p>As @Simon notes, most gas stations accept credit cards.</p></li><li><p>The vast majority of hotels accepts credit cards.</p></li></ul>'}, 'negative': {'<p>I have never had trouble with using a USA swipe credit card in any <i>ATM</i> machine in Europe.</p>'}}\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import InputExample\n",
        "\n",
        "def gen_pairs(queries,qrel,answers):\n",
        "    num_topics = len(queries.keys)\n",
        "    number_training_samples = int(num_topics*0.9)\n",
        "    num_valid_samples = int(num_topics*.05)\n",
        "\n",
        "\n",
        "    ## Preparing the content\n",
        "    counter = 1\n",
        "    train_samples = []\n",
        "    valid_samples = {}\n",
        "    test_samples = {}\n",
        "    for qid in qrel:\n",
        "        # key: doc id, value: relevance score\n",
        "        dic_doc_id_relevance = qrel[qid]\n",
        "        # query text\n",
        "        topic_text = queries[qid]\n",
        "        #\n",
        "        if counter < number_training_samples:\n",
        "            for doc_id in dic_doc_id_relevance:\n",
        "                label = dic_doc_id_relevance[doc_id]\n",
        "                content = answers[doc_id]\n",
        "                if label >= 1:\n",
        "                    label = 1\n",
        "                train_samples.append(InputExample(texts=[topic_text, content], label=label))\n",
        "        elif len(valid_samples) <= num_valid_samples :\n",
        "            for doc_id in dic_doc_id_relevance:\n",
        "                label = dic_doc_id_relevance[doc_id]\n",
        "                if qid not in valid_samples:\n",
        "                    valid_samples[qid] = {'query': topic_text, 'positive': set(), 'negative': set()}\n",
        "                if label == 0:\n",
        "                    label = 'negative'\n",
        "                else:\n",
        "                    label = 'positive'\n",
        "                content = answers[doc_id]\n",
        "                valid_samples[qid][label].add(content)\n",
        "        else:\n",
        "            for doc_id in dic_doc_id_relevance:\n",
        "                label = dic_doc_id_relevance[doc_id]\n",
        "                if qid not in test_samples:\n",
        "                    test_samples[qid] = \n",
        "            \n",
        "        counter += 1\n",
        "    dataset = (train_samples,valid_samples)\n",
        "    #return a tuple of train and validate_samples\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
