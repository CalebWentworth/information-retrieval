{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformers update a few weeks ago made the supplied training code non functional see\n",
    "#https://github.com/UKPLab/sentence-transformers/issues/3021\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from argparse import ArgumentParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caleb/school/information-retrieval/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(string):\n",
    "    cleantext = BeautifulSoup(string, \"lxml\").text\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_topic_file(topic_filepath):\n",
    "    # a method used to read the topic file for this year of the lab; to be passed to BERT/PyTerrier methods\n",
    "    queries = json.load(open(topic_filepath))\n",
    "    result = {}\n",
    "    for item in queries:\n",
    "      # returing results as dictionary of topic id: [title, body, tag]\n",
    "      title =  item['Title'].translate(str.maketrans('', '', string.punctuation))\n",
    "      #removing html from body\n",
    "      body = remove_html(item['Body']).translate(str.maketrans('', '', string.punctuation))\n",
    "      tags = item['Tags']\n",
    "      result[item['Id']] = [title, body, tags]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_qrel_file(qrel_filepath):\n",
    "    # a method used to read the topic file\n",
    "    result = {}\n",
    "    with open(qrel_filepath, \"r\") as f:\n",
    "        reader = csv.reader(f, delimiter='\\t', lineterminator='\\n')\n",
    "        for line in reader:\n",
    "            query_id = line[0]\n",
    "            doc_id = line[2]\n",
    "            score = int(line[3])\n",
    "            if query_id in result:\n",
    "                result[query_id][doc_id] = score\n",
    "            else:\n",
    "                result[query_id] = {doc_id: score}\n",
    "    # dictionary of key:query_id value: dictionary of key:doc id value: score\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_collection(answer_filepath):\n",
    "  # Reading collection to a dictionary\n",
    "  lst = json.load(open(answer_filepath))\n",
    "  result = {}\n",
    "  for doc in lst:\n",
    "    #processes the answers to remove html and punctuation.\n",
    "    result[doc['Id']] = remove_html(doc['Text']).translate(str.maketrans('', '', string.punctuation))\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifies each query to contain the title and body\n",
    "def prep_queries(topics):\n",
    "    queries = {}\n",
    "    for query_id in topics:\n",
    "        queries[query_id] = \"[TITLE]\" + topics[query_id][0] + \"[BODY]\" + topics[query_id][1]\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "def cross_dataset_gen(queries,qrel,answers):\n",
    "    result_list = []\n",
    "    sample_list =[]\n",
    "    for topic in qrel:\n",
    "        print(f\"Key: {topic}, Value: {qrel[topic]}\")\n",
    "        for doc, score in qrel[topic].items():\n",
    "            pair = (queries[topic],answers[doc],score)\n",
    "            result_list.append(pair)\n",
    "\n",
    "    for pair in result_list:\n",
    "        ex_1 = pair[0]\n",
    "        ex_2 = pair[1]\n",
    "        label = pair[2]\n",
    "        if label >=1:\n",
    "            label = 1\n",
    "        sample_list.append(InputExample(texts=[pair[0],pair[1]],label=label))\n",
    "\n",
    "    return sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_dataset_gen(queries,qrel,answers):\n",
    "    mod_queries = {}\n",
    "\n",
    "    for query_id in queries:\n",
    "        mod_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('-i', '--input', required=True, help='search domain file e.g. Answers.json', default=\"Answers.json\")\n",
    "    parser.add_argument('-t', '--topic', required=True, help='topic source files e.g. topics_1.json', default=\"topics_1.json\")\n",
    "    parser.add_argument('-q', '--qrel', required=True, help='qrel source files e.g. qrel_1.tsv', default=\"qrel_1.tsv\")\n",
    "    args = parser.parse_args()\n",
    "    answer_filepath = args.input\n",
    "    topic_filepath = args.topic\n",
    "    qrel_filepath = args.qrel\n",
    "\n",
    "    topics = load_topic_file(topic_filepath)\n",
    "    qrel = read_qrel_file(qrel_filepath)\n",
    "    answers = read_collection(answer_filepath)\n",
    "\n",
    "    queries = prep_queries(topics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = load_topic_file(\"topics_1.json\")\n",
    "qrel = read_qrel_file(\"qrel_1.tsv\")\n",
    "answers = read_collection(\"Answers.json\")\n",
    "queries = prep_queries(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def partition(data):\n",
    "    random.shuffle(data)\n",
    "    n = len(data)\n",
    "    split1 = int(n * 0.8)\n",
    "    split2 = int(n * 0.9)\n",
    "\n",
    "    train = data[:split1]\n",
    "    validation = data[split1:split2]\n",
    "    test = data[split2:]\n",
    "\n",
    "    return train, validation, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sentence_transformers.losses import CoSENTLoss\n",
    "from sentence_transformers import datasets\n",
    "\n",
    "bi_model = SentenceTransformer(\"multi-qa-mpnet-base-cos-v1\")\n",
    "cross_model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "splade_model = 'naver/splade_v2_max'\n",
    "\n",
    "bi_finetune = SentenceTransformer(\"multi-qa-mpnet-base-cos-v1\")\n",
    "bi_loss = CoSENTLoss(bi_finetune)\n",
    "\n",
    "cross_finetune = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "cross_loss = CoSENTLoss(cross_finetune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partition dataset into 80:10:10 sets\n",
    "cross_dataset = cross_dataset_gen(queries,qrel,answers)\n",
    "train_set, validation_set, test_set = partition(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetune Bi encoder\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentencesDataset,\n",
    "    InputExample,\n",
    "    losses,\n",
    "    evaluation,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def fine_tune_bi(model,loss,train,valid,model_name,epochs=10):\n",
    "    \n",
    "    args = SentenceTransformerTrainingArguments(\n",
    "        # Required parameter:\n",
    "        output_dir=\"models/\"+model_name,\n",
    "        # Optional training parameters:\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        learning_rate=2e-5,\n",
    "        warmup_ratio=0.1,\n",
    "        fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "        bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "        batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    )\n",
    "\n",
    "    num_epochs = epochs\n",
    "    model_save_path = \"models/\"+model_name\n",
    "\n",
    "\n",
    "    train_dataloader = DataLoader(train, shuffle=True, batch_size=4)\n",
    "    # During training, we use CESoftmaxAccuracyEvaluator to measure the accuracy on the dev set.\n",
    "\n",
    "    \n",
    "    evaluator = evaluation.EmbeddingSimilarityEvaluator(evaluator_samples_1, evaluator_samples_2, evaluator_samples_score, write_csv=\"evaluation-epoch.csv\")\n",
    "    warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
    "    train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "    train_objectives = [(train_dataloader, loss)]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_objectives=train_objectives,\n",
    "        evaluator=evaluator,\n",
    "        epochs=epochs,\n",
    "        warmup_steps=warmup_steps,\n",
    "        output_path=model_save_path,\n",
    "        save_best_model=True\n",
    "    )\n",
    "    model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tune cross encoder\n",
    "fine_tune_bi(bi_finetune,bi_loss,train_set,validation_set,\"fine_tuned_Bi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning Bi-encoder\n",
    "# Models: https://sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from itertools import islice\n",
    "import json\n",
    "import torch\n",
    "import math\n",
    "import string\n",
    "import csv\n",
    "import random\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "def read_qrel_file(file_path):\n",
    "    # Reading the qrel file\n",
    "    dic_topic_id_answer_id_relevance = {}\n",
    "    with open(file_path) as fd:\n",
    "        rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        for row in rd:\n",
    "            topic_id = row[0]\n",
    "            answer_id = int(row[2])\n",
    "            relevance_score = int(row[3])\n",
    "            if topic_id in dic_topic_id_answer_id_relevance:\n",
    "                dic_topic_id_answer_id_relevance[topic_id][answer_id] = relevance_score\n",
    "            else:\n",
    "                dic_topic_id_answer_id_relevance[topic_id] = {answer_id: relevance_score}\n",
    "    return dic_topic_id_answer_id_relevance\n",
    "\n",
    "\n",
    "def load_topic_file(topic_filepath):\n",
    "    # a method used to read the topic file for this year of the lab; to be passed to BERT/PyTerrier methods\n",
    "    queries = json.load(open(topic_filepath))\n",
    "    result = {}\n",
    "    for item in queries:\n",
    "      # You may do additional preprocessing here\n",
    "\n",
    "      # returing results as dictionary of topic id: [title, body, tag]\n",
    "      title = item['Title'].translate(str.maketrans('', '', string.punctuation))\n",
    "      body = item['Body'].translate(str.maketrans('', '', string.punctuation))\n",
    "      tags = item['Tags']\n",
    "      result[item['Id']] = [title, body, tags]\n",
    "    return result\n",
    "\n",
    "\n",
    "def read_collection(answer_filepath):\n",
    "  # Reading collection to a dictionary\n",
    "  lst = json.load(open(answer_filepath))\n",
    "  result = {}\n",
    "  for doc in lst:\n",
    "    result[int(doc['Id'])] = doc['Text']\n",
    "  return result\n",
    "\n",
    "\n",
    "# Uses the posts file, topic file(s) and qrel file(s) to build our training and evaluation sets.\n",
    "def process_data(queries, train_dic_qrel, val_dic_qrel, collection_dic):\n",
    "    train_samples = []\n",
    "    evaluator_samples_1 = []\n",
    "    evaluator_samples_2 = []\n",
    "    evaluator_samples_score = []\n",
    "\n",
    "    # Build Training set\n",
    "    for topic_id in train_dic_qrel:\n",
    "        question = queries[topic_id]\n",
    "        dic_answer_id = train_dic_qrel.get(topic_id, {})\n",
    "\n",
    "        for answer_id in dic_answer_id:\n",
    "            score = dic_answer_id[answer_id]\n",
    "            answer = collection_dic[answer_id]\n",
    "            if score > 1:\n",
    "                train_samples.append(InputExample(texts=[question, answer], label=1.0))\n",
    "            else:\n",
    "                train_samples.append(InputExample(texts=[question, answer], label=0.0))\n",
    "    for topic_id in val_dic_qrel:\n",
    "        question = queries[topic_id]\n",
    "        dic_answer_id = val_dic_qrel.get(topic_id, {})\n",
    "\n",
    "        for answer_id in dic_answer_id:\n",
    "            score = dic_answer_id[answer_id]\n",
    "            answer = collection_dic[answer_id]\n",
    "            if score > 1:\n",
    "                label = 1.0\n",
    "            elif score == 1:\n",
    "                label = 0.5\n",
    "            else:\n",
    "                label = 0.0\n",
    "            evaluator_samples_1.append(question)\n",
    "            evaluator_samples_2.append(answer)\n",
    "            evaluator_samples_score.append(label)\n",
    "\n",
    "    return train_samples, evaluator_samples_1, evaluator_samples_2, evaluator_samples_score\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_dict(d):\n",
    "    keys = list(d.keys())\n",
    "    random.shuffle(keys)\n",
    "    return {key: d[key] for key in keys}\n",
    "\n",
    "\n",
    "def split_train_validation(qrels, ratio=0.9):\n",
    "    # Using items() + len() + list slicing\n",
    "    # Split dictionary by half\n",
    "    n = len(qrels)\n",
    "    n_split = int(n * ratio)\n",
    "    qrels = shuffle_dict(qrels)\n",
    "    train = dict(islice(qrels.items(), n_split))\n",
    "    validation = dict(islice(qrels.items(), n_split, None))\n",
    "\n",
    "    return train, validation\n",
    "\n",
    "\n",
    "def train(model):\n",
    "\n",
    "    ## reading queries and collection\n",
    "    dic_topics = load_topic_file(\"topics_1.json\")\n",
    "    queries = {}\n",
    "    for query_id in dic_topics:\n",
    "        queries[query_id] = \"[TITLE]\" + dic_topics[query_id][0] + \"[BODY]\" + dic_topics[query_id][1]\n",
    "    qrel = read_qrel_file(\"qrel_1.tsv\")\n",
    "    collection_dic = read_collection('Answers.json')\n",
    "    train_dic_qrel, val_dic_qrel = split_train_validation(qrel)\n",
    "\n",
    "    # print(train_dic_qrel)\n",
    "    # print(val_dic_qrel)\n",
    "\n",
    "    num_epochs = 5\n",
    "    batch_size = 10\n",
    "\n",
    "    # Rename this when training the model and keep track of results\n",
    "    MODEL = \"bi_multi-qa-mpnet-base-cos-v1\"\n",
    "\n",
    "    # Creating train and val dataset\n",
    "    train_samples, evaluator_samples_1, evaluator_samples_2, evaluator_samples_score = process_data(queries, train_dic_qrel, val_dic_qrel, collection_dic)\n",
    "\n",
    "    train_dataset = SentencesDataset(train_samples, model=model)\n",
    "    train_dataloader = DataLoader(train_dataset, shuffle = True, batch_size=batch_size)\n",
    "    train_loss = losses.CoSENTLoss(model=model)\n",
    "\n",
    "    evaluator = evaluation.EmbeddingSimilarityEvaluator(evaluator_samples_1, evaluator_samples_2, evaluator_samples_score, write_csv=\"evaluation-epoch.csv\")\n",
    "    warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "\n",
    "    # add evaluator to the model fit function\n",
    "    model.fit(\n",
    "        train_objectives =[(train_dataloader, train_loss)],\n",
    "        evaluator=evaluator,\n",
    "        epochs=num_epochs,\n",
    "        warmup_steps=warmup_steps,\n",
    "        use_amp=True,\n",
    "        save_best_model=True,\n",
    "        show_progress_bar=True,\n",
    "        output_path=MODEL\n",
    "    )\n",
    "\n",
    "model = SentenceTransformer('multi-qa-mpnet-base-cos-v1')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "print(\"here\")\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning Cross-encoder\n",
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import string\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers import SentenceTransformer, util, CrossEncoder, losses\n",
    "import torch\n",
    "from sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator, CEBinaryClassificationEvaluator, \\\n",
    "    CERerankingEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "\n",
    "def read_qrel_file(qrel_filepath):\n",
    "    # a method used to read the topic file\n",
    "    result = {}\n",
    "    with open(qrel_filepath, \"r\") as f:\n",
    "        reader = csv.reader(f, delimiter='\\t', lineterminator='\\n')\n",
    "        for line in reader:\n",
    "            query_id = line[0]\n",
    "            doc_id = line[2]\n",
    "            score = int(line[3])\n",
    "            if query_id in result:\n",
    "                result[query_id][doc_id] = score\n",
    "            else:\n",
    "                result[query_id] = {doc_id: score}\n",
    "    # dictionary of key:query_id value: dictionary of key:doc id value: score\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_topic_file(topic_filepath):\n",
    "    # a method used to read the topic file for this year of the lab; to be passed to BERT/PyTerrier methods\n",
    "    queries = json.load(open(topic_filepath))\n",
    "    result = {}\n",
    "    for item in queries:\n",
    "      # You may do additional preprocessing here\n",
    "      # returing results as dictionary of topic id: [title, body, tag]\n",
    "      title = item['Title'].translate(str.maketrans('', '', string.punctuation))\n",
    "      body = item['Body'].translate(str.maketrans('', '', string.punctuation))\n",
    "      tags = item['Tags']\n",
    "      result[item['Id']] = [title, body, tags]\n",
    "    return result\n",
    "\n",
    "\n",
    "def read_collection(answer_filepath):\n",
    "  # Reading collection to a dictionary\n",
    "  lst = json.load(open(answer_filepath))\n",
    "  result = {}\n",
    "  for doc in lst:\n",
    "    result[doc['Id']] = doc['Text']\n",
    "  return result\n",
    "\n",
    "\n",
    "## reading queries and collection\n",
    "dic_topics = load_topic_file(\"topics_1.json\")\n",
    "queries = {}\n",
    "for query_id in dic_topics:\n",
    "    queries[query_id] = \"[TITLE]\" + dic_topics[query_id][0] + \"[BODY]\" + dic_topics[query_id][1]\n",
    "qrel = read_qrel_file(\"qrel_1.tsv\")\n",
    "collection_dic = read_collection('Answers.json')\n",
    "\n",
    "## Preparing pairs of training instances\n",
    "num_topics = len(queries.keys())\n",
    "number_training_samples = int(num_topics*0.9)\n",
    "\n",
    "\n",
    "## Preparing the content\n",
    "counter = 1\n",
    "train_samples = []\n",
    "valid_samples = {}\n",
    "for qid in qrel:\n",
    "    # key: doc id, value: relevance score\n",
    "    dic_doc_id_relevance = qrel[qid]\n",
    "    # query text\n",
    "    topic_text = queries[qid]\n",
    "\n",
    "    if counter < number_training_samples:\n",
    "        for doc_id in dic_doc_id_relevance:\n",
    "            label = dic_doc_id_relevance[doc_id]\n",
    "            content = collection_dic[doc_id]\n",
    "            if label >= 1:\n",
    "                label = 1\n",
    "            train_samples.append(InputExample(texts=[topic_text, content], label=label))\n",
    "    else:\n",
    "        for doc_id in dic_doc_id_relevance:\n",
    "            label = dic_doc_id_relevance[doc_id]\n",
    "            if qid not in valid_samples:\n",
    "                valid_samples[qid] = {'query': topic_text, 'positive': set(), 'negative': set()}\n",
    "            if label == 0:\n",
    "                label = 'negative'\n",
    "            else:\n",
    "                label = 'positive'\n",
    "            content = collection_dic[doc_id]\n",
    "            valid_samples[qid][label].add(content)\n",
    "    counter += 1\n",
    "\n",
    "print(\"Training and validation set prepared\")\n",
    "\n",
    "# selecting cross-encoder\n",
    "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "# Learn how to use GPU with this!\n",
    "model = CrossEncoder(model_name)\n",
    "\n",
    "# Adding special tokens\n",
    "tokens = [\"[TITLE]\", \"[BODY]\"]\n",
    "model.tokenizer.add_tokens(tokens, special_tokens=True)\n",
    "model.model.resize_token_embeddings(len(model.tokenizer))\n",
    "\n",
    "num_epochs = 10\n",
    "model_save_path = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=4)\n",
    "# During training, we use CESoftmaxAccuracyEvaluator to measure the accuracy on the dev set.\n",
    "evaluator = CERerankingEvaluator(valid_samples, name='train-eval')\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path,\n",
    "          save_best_model=True)\n",
    "\n",
    "model.save(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "def splade():\n",
    "    \n",
    "    model_id = 'naver/splade_v2_max'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
